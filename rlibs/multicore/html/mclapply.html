<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>R: Parallel version of lapply</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<link rel="stylesheet" type="text/css" href="R.css">
</head><body>

<table width="100%" summary="page for mclapply {multicore}"><tr><td>mclapply {multicore}</td><td align="right">R Documentation</td></tr></table>

<h2>
Parallel version of lapply
</h2>

<h3>Description</h3>

<p><code>mclapply</code> is a parallelized version of <code><a href="../../base/html/lapply.html">lapply</a></code>,
it returns a list of the same length as <code>X</code>, each element of
which is the result of applying <code>FUN</code> to the corresponding
element of <code>X</code>.
</p>


<h3>Usage</h3>

<pre>
mclapply(X, FUN, ..., mc.preschedule = TRUE, mc.set.seed = TRUE,
         mc.silent = FALSE, mc.cores = getOption("cores"), mc.cleanup = TRUE)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>X</code></td>
<td>
<p>a vector (atomic or list) or an expressions vector.  Other
objects (including classed objects) will be coerced by
<code><a href="../../base/html/list.html">as.list</a></code>.</p>
</td></tr>
<tr valign="top"><td><code>FUN</code></td>
<td>
<p>the function to be applied to each element of <code>X</code></p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>optional arguments to <code>FUN</code></p>
</td></tr>
<tr valign="top"><td><code>mc.preschedule</code></td>
<td>
<p>if set to <code>TRUE</code> then the computation is
first divided to (at most) as many jobs are there are cores and then
the jobs are started, each job possibly covering more than one
value. If set to <code>FALSE</code> then one job is spawned for each value
of <code>X</code> sequentially (if used with <code>mc.set.seed=FALSE</code> then
random number sequences will be identical for all values). The former
is better for short computations or large number of values in
<code>X</code>, the latter is better for jobs that have high variance of
completion time and not too many values of <code>X</code>.</p>
</td></tr>
<tr valign="top"><td><code>mc.set.seed</code></td>
<td>
<p>if set to <code>TRUE</code> then each parallel process
first sets its seed to something different from other
processes. Otherwise all processes start with the same (namely
current) seed.</p>
</td></tr>
<tr valign="top"><td><code>mc.silent</code></td>
<td>
<p>if set to <code>TRUE</code> then all output on stdout will be
suppressed for all parallel processes spawned (stderr is not affected).</p>
</td></tr>
<tr valign="top"><td><code>mc.cores</code></td>
<td>
<p>The number of cores to use, i.e. how many processes
will be spawned (at most)</p>
</td></tr>
<tr valign="top"><td><code>mc.cleanup</code></td>
<td>
<p>if set to <code>TRUE</code> then all children that have been
spawned by this function will be killed (by sending <code>SIGTERM</code>)
before this function returns. Under normal circumstances
<code>mclapply</code> waits for the children to deliver results, so this
option usually has only effect when <code>mclapply</code> is interrupted.
If set to <code>FALSE</code> then child processes are collected, but not
forcefully terminated. As a special case this argument can be set to
the signal value that should be used to kill the children instead of
<code>SIGTERM</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mclapply</code> is a parallelized version of <code>lapply</code>, but there
is an important difference: <code>mclapply</code> does not affect the
calling environment in any way, the only side-effect is the delivery
of the result (with the exception of a fall-back to <code>lapply</code> when
there is only one core).
</p>
<p>By default (<code>mc.preschedule=TRUE</code>) the input vector/list <code>X</code>
is split into as many parts as there are cores (currently the values
are spread across the cores sequentially, i.e. first value to core
1, second to core 2, ... (core + 1)-th value to core 1 etc.) and
then one process is spawned to each core and the results are
collected.
</p>
<p>Due to the parallel nature of the execution random numbers are not
sequential (in the random number sequence) as they would be in
<code>lapply</code>. They are sequential for each spawned process, but not
all jobs as a whole.
</p>
<p>In addition, each process is running the job inside <code>try(...,
  silent=TRUE)</code> so if error occur they will be stored as
<code>try-error</code> objects in the list.
</p>
<p>Note: the number of file descriptors is usually limited by the
operating system, so you may have trouble using more than 100 cores
or so (see <code>ulimit -n</code> or similar in your OS documentation)
unless you raise the limit of permissible open file descriptors
(fork will fail with &quot;unable to create a pipe&quot;).
</p>


<h3>Value</h3>

<p>A list.
</p>


<h3>Author(s)</h3>

<p>Simon Urbanek</p>


<h3>See Also</h3>

<p><code><a href="parallel.html">parallel</a></code>, <code><a href="parallel.html">collect</a></code>
</p>


<h3>Examples</h3>

<pre>
  mclapply(1:30, rnorm)
  # use the same random numbers for all values
  set.seed(1)
  mclapply(1:30, rnorm, mc.preschedule=FALSE, mc.set.seed=FALSE)
  # something a bit bigger - albeit still useless :P
  unlist(mclapply(1:32, function(x) sum(rnorm(1e7))))
</pre>

<hr><div align="center">[Package <em>multicore</em> version 0.1-7 <a href="00Index.html">Index</a>]</div>
</body></html>
